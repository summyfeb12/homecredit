{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e44e5ca4e44464ffdcce0e840c543577bd6569bf"
   },
   "source": [
    "# Basic end-to-end training of a LightGBM model\n",
    "_To be added next:_ \n",
    "- An example of Bayesian Optimisation (inspired by the comment in [this kernel](https://www.kaggle.com/tilii7/olivier-lightgbm-parameters-by-bayesian-opt/))- this is not expected to bring singificant improvement, but it is a fun technique to exercise\n",
    "\n",
    "Features that are illustrated in this kernel:\n",
    "- data reading with **memory footprint reduction**\n",
    "- categorical feature encoding using **one-hot-encoding (OHE)**\n",
    "-  internal **category weighting** by _**LightGBM**_ was tuned and no need of resampling is shown\n",
    "- **gradient-boosted decision trees** using _**LightGBM**_ package\n",
    "- **early stopping** in _**LightGBM**_ model training to avoid overtraining\n",
    "- **learning rate decay** in _**LightGBM**_ model training to improve convergence to the minimum\n",
    "- **hyperparameter optimisation** of the model using random search in cross validation\n",
    "- submission preparation\n",
    "This kernel inherited ideas and SW solutions from other public kernels and in such cases I will post direct references to the original product, that that you can get some additional insights from the source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['application_test.csv', 'bureau_balance.csv.zip', 'application_train.csv.zip', 'credit_card_balance.csv.zip', 'application_test.csv.zip', 'HomeCredit_columns_description.csv', 'POS_CASH_balance.csv', 'credit_card_balance.csv', 'installments_payments.csv', 'application_train.csv', 'installments_payments.csv.zip', 'bureau.csv', 'POS_CASH_balance.csv.zip', 'previous_application.csv', 'bureau.csv.zip', 'bureau_balance.csv', 'previous_application.csv.zip', 'sample_submission.csv.zip', 'sample_submission.csv']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline \n",
    "plt.xkcd()\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "PATH = \"data/home-credit-default-risk/\"\n",
    "print(os.listdir(PATH))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0ed4d74b3e586cc5b1be41bf67756e370b86186a"
   },
   "source": [
    "## Read in the data reducing memory pattern for variables.\n",
    "The implementation was copied over from [this kernel](https://www.kaggle.com/gemartin/load-data-reduce-memory-usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "259665371981ab1eeae11333963b96b6099fd9e0",
    "code_folding": [
     0,
     39
    ]
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def import_data(file):\n",
    "    \"\"\"create a dataframe and optimize its memory usage\"\"\"\n",
    "    df = pd.read_csv(file, parse_dates=True, keep_date_col=True)\n",
    "    df = reduce_mem_usage(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 286.23 MB\n",
      "Memory usage after optimization is: 59.54 MB\n",
      "Decreased by 79.2%\n",
      "Memory usage of dataframe is 45.00 MB\n",
      "Memory usage after optimization is: 9.40 MB\n",
      "Decreased by 79.1%\n"
     ]
    }
   ],
   "source": [
    "application_train = import_data(PATH+'application_train.csv')\n",
    "application_test = import_data(PATH+'application_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 471.48 MB\n",
      "Memory usage after optimization is: 130.62 MB\n",
      "Decreased by 72.3%\n"
     ]
    }
   ],
   "source": [
    "# bureau_data = import_data(PATH + 'bureau.csv')\n",
    "# bureau_balance_data = import_data(PATH + 'bureau_balance.csv')\n",
    "previous_applications_data = import_data(PATH + 'previous_application.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bureau data has good number of users covered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "307511"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(application_train['SK_ID_CURR'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_BUREAU</th>\n",
       "      <th>MONTHS_BALANCE</th>\n",
       "      <th>STATUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5715448</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5715448</td>\n",
       "      <td>-1</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5715448</td>\n",
       "      <td>-2</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5715448</td>\n",
       "      <td>-3</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5715448</td>\n",
       "      <td>-4</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_BUREAU  MONTHS_BALANCE STATUS\n",
       "0       5715448               0      C\n",
       "1       5715448              -1      C\n",
       "2       5715448              -2      C\n",
       "3       5715448              -3      C\n",
       "4       5715448              -4      C"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bureau_balance_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "83d85f866b03c50ff1962917db4dd9d149ef6243"
   },
   "source": [
    "The following 2 cells with cleaning criteria were inherited from [this kernel](https://www.kaggle.com/kingychiu/home-credit-eda-distributions-and-outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "a258ddefe97be5807054b3742fb8ab1f18ac62aa"
   },
   "outputs": [],
   "source": [
    "application_train = application_train[application_train['AMT_INCOME_TOTAL'] != 1.170000e+08]\n",
    "application_train = application_train[application_train['AMT_REQ_CREDIT_BUREAU_QRT'] != 261]\n",
    "application_train = application_train[application_train['OBS_30_CNT_SOCIAL_CIRCLE'] < 300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "1a56b73ffe90bdab9015d385d68567cf03617bdf"
   },
   "outputs": [],
   "source": [
    "application_train['DAYS_EMPLOYED'] = (application_train['DAYS_EMPLOYED'].apply(lambda x: x if x != 365243 else np.nan))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5fb1ac77952823a894bede3dc852b942bf6ee4a7"
   },
   "source": [
    "## Additional numerical columns constructed from EXT_SOURCE_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "3b5d60b0df693c67fbb18f68f9123e0b2b3ae7e0"
   },
   "outputs": [],
   "source": [
    "def feat_ext_source(df):\n",
    "    x1 = df['EXT_SOURCE_1'].fillna(-1) + 1e-1\n",
    "    x2 = df['EXT_SOURCE_2'].fillna(-1) + 1e-1\n",
    "    x3 = df['EXT_SOURCE_3'].fillna(-1) + 1e-1\n",
    "    \n",
    "    df['EXT_SOURCE_1over2_NAminus1_Add0.1'] = x1/x2\n",
    "    df['EXT_SOURCE_2over1_NAminus1_Add0.1'] = x2/x1\n",
    "    df['EXT_SOURCE_1over3_NAminus1_Add0.1'] = x1/x3\n",
    "    df['EXT_SOURCE_3over1_NAminus1_Add0.1'] = x3/x1\n",
    "    df['EXT_SOURCE_2over3_NAminus1_Add0.1'] = x2/x3\n",
    "    df['EXT_SOURCE_3over2_NAminus1_Add0.1'] = x3/x2\n",
    "    \n",
    "    df['EXT_SOURCE_na1_2'] = (application_train['EXT_SOURCE_1'].isnull()) * (application_train['EXT_SOURCE_2'].fillna(0))\n",
    "    df['EXT_SOURCE_na1_3'] = (application_train['EXT_SOURCE_1'].isnull()) * (application_train['EXT_SOURCE_3'].fillna(0))\n",
    "    df['EXT_SOURCE_na2_1'] = (application_train['EXT_SOURCE_2'].isnull()) * (application_train['EXT_SOURCE_1'].fillna(0))\n",
    "    df['EXT_SOURCE_na2_3'] = (application_train['EXT_SOURCE_2'].isnull()) * (application_train['EXT_SOURCE_3'].fillna(0))\n",
    "    df['EXT_SOURCE_na3_1'] = (application_train['EXT_SOURCE_3'].isnull()) * (application_train['EXT_SOURCE_1'].fillna(0))\n",
    "    df['EXT_SOURCE_na3_2'] = (application_train['EXT_SOURCE_3'].isnull()) * (application_train['EXT_SOURCE_2'].fillna(0))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "aa46a91e767414557d54b0fa9d79bfc013812289"
   },
   "outputs": [],
   "source": [
    "application_train = feat_ext_source(application_train)\n",
    "application_test  = feat_ext_source(application_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "87bce4fc7ddd06b3778cd5c0bcf99bcde57ce0ab"
   },
   "source": [
    "## Categorical encoding\n",
    "The function was taken from [this kernel](https://www.kaggle.com/sz8416/simple-intro-eda-baseline-model-with-gridsearch). It allows to do OneHotEncoding (OHE) keeping only those columns that are common to train and test samples. OHE is performed using `pd.get_dummies`, which allows to convert categorical features, while keeping numerical untouched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "f4114dfe218a34a532275add442cb92a0414b3a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of train increases from 79.86 to 115.22 MB\n",
      "Memory usage of test increases from 10.51 to 16.13 MB\n"
     ]
    }
   ],
   "source": [
    "# use this if you want to convert categorical features to dummies(default)\n",
    "def cat_to_dummy(train, test):\n",
    "    train_d = pd.get_dummies(train, drop_first=False)\n",
    "    test_d = pd.get_dummies(test, drop_first=False)\n",
    "    # make sure that the number of features in train and test should be same\n",
    "    for i in train_d.columns:\n",
    "        if i not in test_d.columns:\n",
    "            if i!='TARGET':\n",
    "                train_d = train_d.drop(i, axis=1)\n",
    "    for j in test_d.columns:\n",
    "        if j not in train_d.columns:\n",
    "            if j!='TARGET':\n",
    "                test_d = test_d.drop(i, axis=1)\n",
    "    print('Memory usage of train increases from {:.2f} to {:.2f} MB'.format(train.memory_usage().sum() / 1024**2, \n",
    "                                                                            train_d.memory_usage().sum() / 1024**2))\n",
    "    print('Memory usage of test increases from {:.2f} to {:.2f} MB'.format(test.memory_usage().sum() / 1024**2, \n",
    "                                                                            test_d.memory_usage().sum() / 1024**2))\n",
    "    return train_d, test_d\n",
    "\n",
    "application_train_ohe, application_test_ohe = cat_to_dummy(application_train, application_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bfa35f60c92ae01d6de9c82ef52ffc1a0c00350d"
   },
   "source": [
    "## Deal with category imbalance\n",
    "Use a standard library (`imblearn`) to to random undersampling on the dominating category. Use if if you want to repeat the HP optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "f62e64bf4e4d4329a0c4216651b287cea8f3100d"
   },
   "outputs": [],
   "source": [
    "# You can use the full sample and do sample weighting in lightgbm using `is_unbalance` OR `scale_pos_weight` argument\n",
    "# But it makes the code to run 8x..10x slower, which is ok for the run with pre-optimised parametersm but is too slow for HP optimisation\n",
    "X_rus, y_rus = (application_train_ohe.drop(['SK_ID_CURR', 'TARGET'], axis=1),\n",
    "                application_train_ohe['TARGET'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "077f571d694f0b446b0c2b84991bf91071d84ce0"
   },
   "source": [
    "# Model fitting with HyperParameter optimisation\n",
    "We will use LightGBM classifier - LightGBM allows to build very sophysticated models with a very short training time.\n",
    "### Split the full sample into train/test (80/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "4c9053167195838284544e5d717c1c68b27b46fb"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_rus, y_rus, test_size=0.20, random_state=314, stratify=y_rus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "08cb13d0caa3713665f843db8a83de6744210f83"
   },
   "source": [
    "### Prepare learning rate shrinkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "a746df8c0f27948f76f476b7329bf11449d25f38"
   },
   "outputs": [],
   "source": [
    "def learning_rate_010_decay_power_0995(current_iter):\n",
    "    base_learning_rate = 0.1\n",
    "    lr = base_learning_rate  * np.power(.995, current_iter)\n",
    "    return lr if lr > 1e-3 else 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b8af9e2ff9ca6f6bb59b7380bc65c99a5063f4c7"
   },
   "source": [
    "### Use test subset for early stopping criterion \n",
    "This allows us to avoid overtraining and we do not need to optimise the number of trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "f565eef3d14a6d8ade0602823dcd316ad2829117",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "fit_params={\"early_stopping_rounds\":30, \n",
    "            \"eval_metric\" : 'auc', \n",
    "            \"eval_set\" : [(X_test,y_test)],\n",
    "            'eval_names': ['valid'],\n",
    "            'verbose': 100,\n",
    "            'categorical_feature': 'auto'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "edcf7716984b1f0ed56d4d325d0ddee2efe7c017"
   },
   "source": [
    "### Set up HyperParameter search\n",
    "We use random search, which is more flexible and more efficient than a grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "8a1c436c90043f3ade05d149f4714ccf5bbf15aa"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "param_test ={'num_leaves': sp_randint(6, 50), \n",
    "             'min_child_samples': sp_randint(100, 500), \n",
    "             'min_child_weight': [1e-5, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4],\n",
    "             'subsample': sp_uniform(loc=0.2, scale=0.8), \n",
    "             'colsample_bytree': sp_uniform(loc=0.4, scale=0.6),\n",
    "             'reg_alpha': [0, 1e-1, 1, 2, 5, 7, 10, 50, 100],\n",
    "             'reg_lambda': [0, 1e-1, 1, 5, 10, 20, 50, 100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "5bb7998f3db77da6fc23737bbf8d80a260391f24"
   },
   "outputs": [],
   "source": [
    "#This parameter defines the number of HP points to be tested\n",
    "n_HP_points_to_test = 100\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "#n_estimators is set to a \"large value\". The actual number of trees build will depend on early stopping and 1000 define only the absolute maximum\n",
    "clf = lgb.LGBMClassifier(max_depth=-1, random_state=314, silent=True, metric='None', n_jobs=4, n_estimators=1000)\n",
    "gs = RandomizedSearchCV(\n",
    "    estimator=clf, param_distributions=param_test, \n",
    "    n_iter=n_HP_points_to_test,\n",
    "    scoring='roc_auc',\n",
    "    cv=3,\n",
    "    refit=True,\n",
    "    random_state=314,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3ab1e4e2b4726f0d1864ec085c1929a2c4d3dba1"
   },
   "source": [
    "Run this cell, to do HP optimisation. To save time `opt_parameters` was directly hardcoded below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_uuid": "1d6c7e208287046714f376085cb3745da63ad7e1"
   },
   "outputs": [],
   "source": [
    "#gs.fit(X_train, y_train, **fit_params)\n",
    "#print('Best score reached: {} with params: {} '.format(gs.best_score_, gs.best_params_))\n",
    "\n",
    "# Derived optimal parameters\n",
    "opt_parameters = {'colsample_bytree': 0.9234, 'min_child_samples': 399, 'min_child_weight': 0.1, 'num_leaves': 13, 'reg_alpha': 2, 'reg_lambda': 5, 'subsample': 0.855}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7ec17e1e5fec8b04a1602f4524486848deda39a9"
   },
   "source": [
    "## Tune the weights of unbalanced classes\n",
    "Following discussion in [this comment](https://www.kaggle.com/mlisovyi/modular-good-fun-with-ligthgbm/comments#337494), there was a small tuning of the disbalanced sample weight:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "01da6dd7dd86c2d62fd4858765ffe5a45c7e9f7b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "[100]\tvalid's auc: 0.759816\n",
      "[200]\tvalid's auc: 0.76221\n",
      "Early stopping, best iteration is:\n",
      "[245]\tvalid's auc: 0.762896\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "[100]\tvalid's auc: 0.759881\n",
      "[200]\tvalid's auc: 0.761922\n",
      "Early stopping, best iteration is:\n",
      "[247]\tvalid's auc: 0.76242\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "[100]\tvalid's auc: 0.759562\n",
      "[200]\tvalid's auc: 0.76207\n",
      "Early stopping, best iteration is:\n",
      "[243]\tvalid's auc: 0.762424\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "[100]\tvalid's auc: 0.760529\n",
      "[200]\tvalid's auc: 0.76274\n",
      "Early stopping, best iteration is:\n",
      "[216]\tvalid's auc: 0.762966\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "[100]\tvalid's auc: 0.759274\n",
      "[200]\tvalid's auc: 0.762619\n",
      "Early stopping, best iteration is:\n",
      "[227]\tvalid's auc: 0.762841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds.\n",
      "[100]\tvalid's auc: 0.760315\n",
      "[200]\tvalid's auc: 0.763138\n",
      "[300]\tvalid's auc: 0.764111\n",
      "Early stopping, best iteration is:\n",
      "[317]\tvalid's auc: 0.764332\n",
      "Best score reached: 0.7580154546150611 with params: {'scale_pos_weight': 1} \n"
     ]
    }
   ],
   "source": [
    "clf_sw = lgb.LGBMClassifier(**clf.get_params())\n",
    "#set optimal parameters\n",
    "clf_sw.set_params(**opt_parameters)\n",
    "\n",
    "gs_sample_weight = GridSearchCV(estimator=clf_sw, \n",
    "                                param_grid={'scale_pos_weight':[1]},\n",
    "                                scoring='roc_auc',\n",
    "                                cv=5,\n",
    "                                refit=True,\n",
    "                                verbose=True)\n",
    "\n",
    "gs_sample_weight.fit(X_train, y_train, **fit_params)\n",
    "print('Best score reached: {} with params: {} '.format(gs_sample_weight.best_score_, gs_sample_weight.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "83272a6ccf734a4b8b262022c0b326ad8c611bc1"
   },
   "source": [
    "As an outcome, precision of the classifier does not depend much on the internal class weighting, but `weight=1` still turns out to give slightly better performance that weighted scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a4362d5fd50f429e8157996c4a20da5ef1069711"
   },
   "source": [
    "### Look at the performance of the top-5 parameter choices\n",
    "(the list is inverted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "_uuid": "d292f90f371aa3f9c614a694fdd4b64fe0476845",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(\"Valid+-Std     Train  :   Parameters\")\n",
    "#for i in np.argsort(gs.cv_results_['mean_test_score'])[-5:]:\n",
    "#    print('{1:.3f}+-{3:.3f}     {2:.3f}   :  {0}'.format(gs.cv_results_['params'][i], \n",
    "#                                    gs.cv_results_['mean_test_score'][i], \n",
    "#                                    gs.cv_results_['mean_train_score'][i],\n",
    "#                                    gs.cv_results_['std_test_score'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_uuid": "cac81e2ddb8deeabc0c4d555d0ae66c4b88c1d82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid+-Std     Train  :   Parameters\n",
      "0.758+-0.003     0.791   :  {'scale_pos_weight': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nitin/.local/share/virtualenvs/ownwork-7IQXCDiI/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "print(\"Valid+-Std     Train  :   Parameters\")\n",
    "for i in np.argsort(gs_sample_weight.cv_results_['mean_test_score'])[-5:]:\n",
    "    print('{1:.3f}+-{3:.3f}     {2:.3f}   :  {0}'.format(gs_sample_weight.cv_results_['params'][i], \n",
    "                                    gs_sample_weight.cv_results_['mean_test_score'][i], \n",
    "                                    gs_sample_weight.cv_results_['mean_train_score'][i],\n",
    "                                    gs_sample_weight.cv_results_['std_test_score'][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "af7d792fa3b44bbf11bec995032c95bfacf12ee2"
   },
   "source": [
    "## Build the final model\n",
    "We do training with the 0.8 subset of the dataset and 0.2 subset for early stopping. We use the tuned parameter values but a smaller learning rate to allow smoother convergence to the minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "_uuid": "53bb37030e953d3e5d332e5886997de9925109e0",
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Configure from the HP optimisation\n",
    "#clf_final = lgb.LGBMClassifier(**gs.best_estimator_.get_params())\n",
    "\n",
    "#Configure locally from hardcoded values\n",
    "clf_final = lgb.LGBMClassifier(**clf.get_params())\n",
    "#set optimal parameters\n",
    "clf_final.set_params(**opt_parameters)\n",
    "\n",
    "#force larger number of max trees and smaller learning rate\n",
    "clf_final.set_params(n_estimators=5000, learning_rate=0.005, objective='binary')\n",
    "clf_final.fit(X_train, y_train, **fit_params, callbacks=[lgb.reset_parameter(learning_rate=learning_rate_010_decay_power_0995)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1d7b27535ec0dfdfe5ae599d3120d714487de4ec"
   },
   "source": [
    "### Plot feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "_uuid": "f92343b2289eeac9ff3006bb8efcf8591ad89f2b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_imp = pd.Series(clf_final.feature_importances_, index=application_train_ohe.drop(['SK_ID_CURR', 'TARGET'], axis=1).columns)\n",
    "feat_imp.nlargest(20).plot(kind='barh', figsize=(8,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5b6ab3bf6034170547105ab835b65503e9f5e3f7"
   },
   "source": [
    "# Predict on the submission test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "377aa88c83f9821fd9f1e7147b78584fbfaa9bb3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probabilities = clf_final.predict_proba(application_test_ohe.drop(['SK_ID_CURR'], axis=1))\n",
    "submission = pd.DataFrame({\n",
    "    'SK_ID_CURR': application_test_ohe['SK_ID_CURR'],\n",
    "    'TARGET':     [ row[1] for row in probabilities]\n",
    "})\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cb372267b91470fb7579a5fe38f77e6cd8e48a0c",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
